{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8209cb1f",
   "metadata": {},
   "source": [
    "## Import Libraries and Setup Argoverse Stereo Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74e5787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import plotly.graph_objects as go\n",
    "from PSMNet.models import *\n",
    "import pandas as pd\n",
    "\n",
    "from argoverse.data_loading.stereo_dataloader import ArgoverseStereoDataLoader\n",
    "from argoverse.evaluation.stereo.eval import StereoEvaluator\n",
    "from argoverse.utils.calibration import get_calibration_config\n",
    "from argoverse.utils.camera_stats import RECTIFIED_STEREO_CAMERA_LIST\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "STEREO_FRONT_LEFT_RECT = RECTIFIED_STEREO_CAMERA_LIST[0]\n",
    "STEREO_FRONT_RIGHT_RECT = RECTIFIED_STEREO_CAMERA_LIST[1]\n",
    "\n",
    "\n",
    "# Path to the dataset (please change accordingly).\n",
    "data_dir = \"/home/cmiller/Documents/Curtis_Classes/CMPE_249/Project/code/argoverse_stereo_v1.1/\"\n",
    "\n",
    "# Choosing the data split: train, val, or test (note that we do not provide ground truth for the test set).\n",
    "split_name = \"val\"\n",
    "\n",
    "# Choosing a specific log id. For example, 273c1883-673a-36bf-b124-88311b1a80be.\n",
    "log_ids = os.listdir('./argoverse_stereo_v1.1/rectified_stereo_images_v1.1/val/')\n",
    "\n",
    "# Creating the Argoverse Stereo data loader.\n",
    "stereo_data_loader = ArgoverseStereoDataLoader(data_dir, split_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ba787",
   "metadata": {},
   "source": [
    "## Generate Video of Results from Stereo Matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5b7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Paths to Image Data\n",
    "DMDirectory = './results/stereo_match_results/70d2aea5-dbeb-333d-b21e-76a7f2f1ba1c/'\n",
    "ImageDirectory = './argoverse_stereo_v1.1/rectified_stereo_images_v1.1/val/70d2aea5-dbeb-333d-b21e-76a7f2f1ba1c/stereo_front_left_rect/'\n",
    "ErrorDirectory = './results/stereo_match_error_results/70d2aea5-dbeb-333d-b21e-76a7f2f1ba1c/'\n",
    "\n",
    "# Get all images from training result directory\n",
    "images = sorted([image for image in os.listdir(ImageDirectory) if image.endswith(\".jpg\")])\n",
    "dms = sorted([image for image in os.listdir(DMDirectory) if image.endswith(\".png\")])\n",
    "errors = sorted([image for image in os.listdir(ErrorDirectory) if image.endswith(\".png\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4c09c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read single image to get size of image\n",
    "image = cv2.imread(os.path.join(ImageDirectory, images[0]))\n",
    "dm = cv2.imread(os.path.join(DMDirectory, dms[0]))\n",
    "error = cv2.imread(os.path.join(ErrorDirectory, errors[0]))\n",
    "\n",
    "# Define size of video frame as 1/4 of combined size\n",
    "imgHeight, imgWidth, _ = image.shape\n",
    "dmHeight, dmWidth, _ = dm.shape\n",
    "errorHeight, errorWidth, _ = error.shape\n",
    "height = int(imgHeight/4)\n",
    "width = int((imgWidth + dmWidth + errorWidth)/4)\n",
    "\n",
    "# Loop through each image and place in video\n",
    "for i in range(0, len(images)):\n",
    "    \n",
    "    # Load images\n",
    "    image = cv2.imread(os.path.join(ImageDirectory, images[i]))\n",
    "    dm = cv2.imread(os.path.join(DMDirectory, dms[i]))\n",
    "    error = cv2.imread(os.path.join(ErrorDirectory, errors[i]))\n",
    "    \n",
    "    # Downsample images\n",
    "    image = cv2.resize(image, (0, 0), None, .25, .25)\n",
    "    dm = cv2.resize(dm, (0, 0), None, .25, .25)\n",
    "    error = cv2.resize(error, (0, 0), None, .25, .25)\n",
    "    \n",
    "    # Combine images and write to video\n",
    "    numpy_vertical = np.hstack((image, dm, error))\n",
    "    video.write(numpy_vertical)\n",
    "\n",
    "# Close Video\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af126578",
   "metadata": {},
   "source": [
    "## Generate Video of Results from PSMNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65cda025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Paths to Image Data\n",
    "DMDirectory = './results/PSMNet_results//70d2aea5-dbeb-333d-b21e-76a7f2f1ba1c/'\n",
    "ImageDirectory = './argoverse_stereo_v1.1/rectified_stereo_images_v1.1/val/70d2aea5-dbeb-333d-b21e-76a7f2f1ba1c/stereo_front_left_rect/'\n",
    "ErrorDirectory = './results/PSMNet_error_results//70d2aea5-dbeb-333d-b21e-76a7f2f1ba1c/'\n",
    "\n",
    "# Get all images from training result directory\n",
    "images = sorted([image for image in os.listdir(ImageDirectory) if image.endswith(\".jpg\")])\n",
    "dms = sorted([image for image in os.listdir(DMDirectory) if image.endswith(\".png\")])\n",
    "errors = sorted([image for image in os.listdir(ErrorDirectory) if image.endswith(\".png\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ade30dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read single image to get size of image\n",
    "image = cv2.imread(os.path.join(ImageDirectory, images[0]))\n",
    "dm = cv2.imread(os.path.join(DMDirectory, dms[0]))\n",
    "error = cv2.imread(os.path.join(ErrorDirectory, errors[0]))\n",
    "\n",
    "# Define size of video frame as 1/4 of combined size\n",
    "imgHeight, imgWidth, _ = image.shape\n",
    "dmHeight, dmWidth, _ = dm.shape\n",
    "errorHeight, errorWidth, _ = error.shape\n",
    "height = int(imgHeight/4)\n",
    "width = int((imgWidth + dmWidth + errorWidth)/4)\n",
    "\n",
    "# Start video \n",
    "video = cv2.VideoWriter('./results/PSMNet_results.avi', 0, 3, (width, height))\n",
    "\n",
    "# Loop through each image and place in video\n",
    "for i in range(0, len(images)):\n",
    "    \n",
    "    # Load images\n",
    "    image = cv2.imread(os.path.join(ImageDirectory, images[i]))\n",
    "    dm = cv2.imread(os.path.join(DMDirectory, dms[i]))\n",
    "    error = cv2.imread(os.path.join(ErrorDirectory, errors[i]))\n",
    "    \n",
    "    # Downsample images\n",
    "    image = cv2.resize(image, (0, 0), None, .25, .25)\n",
    "    dm = cv2.resize(dm, (0, 0), None, .25, .25)\n",
    "    error = cv2.resize(error, (0, 0), None, .25, .25)\n",
    "    \n",
    "    # Combine images and write to video\n",
    "    numpy_vertical = np.hstack((image, dm, error))\n",
    "    video.write(numpy_vertical)\n",
    "\n",
    "# Close Video\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377749a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
