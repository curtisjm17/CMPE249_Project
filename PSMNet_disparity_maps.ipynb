{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db2054e8",
   "metadata": {},
   "source": [
    "## Import Libraries and Setup Argoverse Stereo Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28491ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import plotly.graph_objects as go\n",
    "from PSMNet.models import *\n",
    "import pandas as pd\n",
    "\n",
    "from argoverse.data_loading.stereo_dataloader import ArgoverseStereoDataLoader\n",
    "from argoverse.evaluation.stereo.eval import StereoEvaluator\n",
    "from argoverse.utils.calibration import get_calibration_config\n",
    "from argoverse.utils.camera_stats import RECTIFIED_STEREO_CAMERA_LIST\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "STEREO_FRONT_LEFT_RECT = RECTIFIED_STEREO_CAMERA_LIST[0]\n",
    "STEREO_FRONT_RIGHT_RECT = RECTIFIED_STEREO_CAMERA_LIST[1]\n",
    "\n",
    "\n",
    "# Path to the dataset (please change accordingly).\n",
    "data_dir = \"./argoverse_stereo_v1.1/\"\n",
    "\n",
    "# Choosing the data split: train, val, or test (note that we do not provide ground truth for the test set).\n",
    "split_name = \"val\"\n",
    "\n",
    "# Choosing a specific log id. For example, 273c1883-673a-36bf-b124-88311b1a80be.\n",
    "log_ids = os.listdir('./argoverse_stereo_v1.1/rectified_stereo_images_v1.1/val/')\n",
    "\n",
    "# Creating the Argoverse Stereo data loader.\n",
    "stereo_data_loader = ArgoverseStereoDataLoader(data_dir, split_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9e8ce",
   "metadata": {},
   "source": [
    "## Define Function to Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2351fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that loads pre-trained model\n",
    "def configure_PSMNet_model(loadmodel,\n",
    "                           model_struct,\n",
    "                           maxdisp=192,\n",
    "                           no_cuda=False,\n",
    "                           seed=1):\n",
    "    \n",
    "    # Configure Cude and Torch\n",
    "    args_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(seed)\n",
    "    if args_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "    # Pick model structure based on input\n",
    "    if model_struct == 'stackhourglass':\n",
    "        model = stackhourglass(maxdisp)\n",
    "    elif model_struct == 'basic':\n",
    "        model = basic(maxdisp)\n",
    "    else:\n",
    "        print('no model')\n",
    "\n",
    "    # Initial model\n",
    "    model = nn.DataParallel(model, device_ids=[0])\n",
    "    model.cuda()\n",
    "    \n",
    "    # Load model parameter values\n",
    "    if loadmodel is not None:\n",
    "        print('load PSMNet')\n",
    "        state_dict = torch.load(loadmodel)\n",
    "        model.load_state_dict(state_dict['state_dict'])\n",
    "\n",
    "    print('Number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "    return model, args_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c9a4f",
   "metadata": {},
   "source": [
    "## Define Function to Produce Disparity Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5023ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a disparity map from stereo image pair\n",
    "def test(model,args_cuda,imgL,imgR):\n",
    "    model.eval()\n",
    "\n",
    "    # Convert images to cuda\n",
    "    if args_cuda:\n",
    "        imgL = imgL.cuda()\n",
    "        imgR = imgR.cuda()     \n",
    "\n",
    "    # Produce disparity map from images\n",
    "    with torch.no_grad():\n",
    "        disp = model(imgL,imgR)\n",
    "\n",
    "    # COnvert disparity model to numpy array\n",
    "    disp = torch.squeeze(disp)\n",
    "    pred_disp = disp.data.cpu().numpy()\n",
    "\n",
    "    return pred_disp\n",
    "\n",
    "# Produce disparity map from input model and stereo image pairs\n",
    "def testImagePSMNet(model, args_cuda, log_id, leftimg, rightimg):\n",
    "    \n",
    "    # Load stereo image pair\n",
    "    imgL_o = Image.open(leftimg).convert('RGB')\n",
    "    imgR_o = Image.open(rightimg).convert('RGB')\n",
    "\n",
    "    # Resize image to fit in GPU memory\n",
    "    height, width = imgL_o.size\n",
    "    newsize = (int(height*0.25), int(width*0.25))\n",
    "    imgL_o = imgL_o.resize(newsize)\n",
    "    imgR_o = imgR_o.resize(newsize)\n",
    "    \n",
    "    # Adjust images to be consistent with trainging images\n",
    "    normal_mean_var = {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}\n",
    "    infer_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(**normal_mean_var)])    \n",
    "    imgL = infer_transform(imgL_o)\n",
    "    imgR = infer_transform(imgR_o) \n",
    "\n",
    "    # pad to width and hight to 16 times\n",
    "    if imgL.shape[1] % 16 != 0:\n",
    "        times = imgL.shape[1]//16       \n",
    "        top_pad = (times+1)*16 -imgL.shape[1]\n",
    "    else:\n",
    "        top_pad = 0\n",
    "\n",
    "    if imgL.shape[2] % 16 != 0:\n",
    "        times = imgL.shape[2]//16                       \n",
    "        right_pad = (times+1)*16-imgL.shape[2]\n",
    "    else:\n",
    "        right_pad = 0    \n",
    "    imgL = F.pad(imgL,(0,right_pad, top_pad,0)).unsqueeze(0)\n",
    "    imgR = F.pad(imgR,(0,right_pad, top_pad,0)).unsqueeze(0)\n",
    "\n",
    "    # Produce disparity map for stereo pair\n",
    "    pred_disp = test(model, args_cuda, imgL, imgR)\n",
    "    \n",
    "    # Remove padding from disparity map\n",
    "    if top_pad !=0 and right_pad != 0:\n",
    "        img = pred_disp[top_pad:,:-right_pad]\n",
    "    elif top_pad ==0 and right_pad != 0:\n",
    "        img = pred_disp[:,:-right_pad]\n",
    "    elif top_pad !=0 and right_pad == 0:\n",
    "        img = pred_disp[top_pad:,:]\n",
    "    else:\n",
    "        img = pred_disp\n",
    "    \n",
    "    # Format disparity map and resize to full scale\n",
    "    newsize = (height, width)\n",
    "    img = (img * 4 * 256).astype('uint16')\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.resize(newsize)\n",
    "\n",
    "    # Save disparity map results\n",
    "    timestamp = int(Path(leftimg).stem.split(\"_\")[-1])\n",
    "    save_dir_disp = f\"./results/PSMNet_results/{log_id}/\"\n",
    "    Path(save_dir_disp).mkdir(parents=True, exist_ok=True)\n",
    "    filename = f\"{save_dir_disp}/disparity_{timestamp}.png\"\n",
    "    img.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b01161",
   "metadata": {},
   "source": [
    "## Load PSMNet and and Test Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d900ced6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained PSMNet Model\n",
      "load PSMNet\n",
      "Number of model parameters: 5224768\n",
      "Creating Disparity Maps for Test Image set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmiller/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 93.56798481941223 Time per Image: 1.299555351336797\n",
      "Elapsed Time: 193.993421792984 Time per Image: 1.3287220719742447\n",
      "Elapsed Time: 351.7331702709198 Time per Image: 1.3902496876923933\n",
      "Elapsed Time: 460.9530074596405 Time per Image: 1.409642226834545\n",
      "Elapsed Time: 564.4595625400543 Time per Image: 1.4290115525450888\n",
      "Elapsed Time: 675.8954269886017 Time per Image: 1.4442209998766582\n",
      "Elapsed Time: 787.4165678024292 Time per Image: 1.452798096456211\n",
      "Elapsed Time: 899.8618860244751 Time per Image: 1.4608147508138185\n",
      "Elapsed Time: 1118.9135887622833 Time per Image: 1.4741944525395771\n",
      "Elapsed Time: 1228.6609108448029 Time per Image: 1.476755903317378\n",
      "Elapsed Time: 1391.4110708236694 Time per Image: 1.4849637900752473\n",
      "Elapsed Time: 1502.791784286499 Time per Image: 1.487912658181521\n",
      "Elapsed Time: 1725.4919848442078 Time per Image: 1.4926401257102464\n",
      "Elapsed Time: 1836.3080804347992 Time per Image: 1.4929333993089877\n",
      "Elapsed Time: 1948.0599575042725 Time per Image: 1.4950575272303221\n",
      "Elapsed Time: 2169.361698627472 Time per Image: 1.4981779691593422\n",
      "Elapsed Time: 2282.245082616806 Time per Image: 1.4995039970896717\n"
     ]
    }
   ],
   "source": [
    "# Load PSMNet pretrained model\n",
    "print(\"Loading pre-trained PSMNet Model\")\n",
    "modelPSMNet, args_cuda = configure_PSMNet_model('./PSMNet/pretrained_model_KITTI2015.tar',\n",
    "                                                'stackhourglass', 192)\n",
    "\n",
    "# Put each stereo pair through inference pipeline\n",
    "t0 = time.time()\n",
    "imageCount = 0\n",
    "print('Creating Disparity Maps for Test Image set')\n",
    "\n",
    "# Loop through each log\n",
    "for log_id in log_ids:\n",
    "    \n",
    "    # Loading the left rectified stereo image paths for the chosen log.\n",
    "    left_stereo_img_fpaths = stereo_data_loader.get_ordered_log_stereo_image_fpaths(\n",
    "        log_id=log_id,\n",
    "        camera_name=STEREO_FRONT_LEFT_RECT)\n",
    "    \n",
    "    # Loading the right rectified stereo image paths for the chosen log.\n",
    "    right_stereo_img_fpaths = stereo_data_loader.get_ordered_log_stereo_image_fpaths(\n",
    "        log_id=log_id,\n",
    "        camera_name=STEREO_FRONT_RIGHT_RECT)\n",
    "    \n",
    "    # Loop through each image in specific log\n",
    "    for idx in range(0,len(left_stereo_img_fpaths)):\n",
    "        testImagePSMNet(modelPSMNet, args_cuda, log_id, left_stereo_img_fpaths[idx], right_stereo_img_fpaths[idx])\n",
    "    \n",
    "    # Report status and latency\n",
    "    imageCount = imageCount + len(left_stereo_img_fpaths) \n",
    "    print('Elapsed Time:', time.time()-t0, 'Time per Image:', (time.time()-t0)/imageCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf7b001",
   "metadata": {},
   "source": [
    "## Get Performance Results from Disparity Map Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87ca2811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 15.410041093826294\n",
      "Elapsed Time: 31.57341456413269\n",
      "Elapsed Time: 53.35528588294983\n",
      "Elapsed Time: 70.06567811965942\n",
      "Elapsed Time: 85.68302917480469\n",
      "Elapsed Time: 101.5634183883667\n",
      "Elapsed Time: 118.16903924942017\n",
      "Elapsed Time: 134.73144793510437\n",
      "Elapsed Time: 164.47940135002136\n",
      "Elapsed Time: 180.49587106704712\n",
      "Elapsed Time: 202.35144019126892\n",
      "Elapsed Time: 219.06235003471375\n",
      "Elapsed Time: 251.18495297431946\n",
      "Elapsed Time: 269.6106233596802\n",
      "Elapsed Time: 288.81002497673035\n",
      "Elapsed Time: 324.3024377822876\n",
      "Elapsed Time: 341.3530025482178\n",
      "Results for Full Images\n",
      "==============================\n",
      "{\n",
      "    \"all:10\": 9.796292466655133,\n",
      "    \"fg:10\": 11.024064570773753,\n",
      "    \"bg:10\": 9.477696348582793,\n",
      "    \"all*:10\": 9.796291328198063,\n",
      "    \"fg*:10\": 11.02405921379918,\n",
      "    \"bg*:10\": 9.477696348582793,\n",
      "    \"all:5\": 46.348040605867205,\n",
      "    \"fg:5\": 43.19114041703676,\n",
      "    \"bg:5\": 47.16722858214497,\n",
      "    \"all*:5\": 46.348040502453884,\n",
      "    \"fg*:5\": 43.19113948120579,\n",
      "    \"bg*:5\": 47.16722858214497,\n",
      "    \"all:3\": 50.664212847820714,\n",
      "    \"fg:3\": 46.16692809491821,\n",
      "    \"bg:3\": 51.83121889017516,\n",
      "    \"all*:3\": 50.66421286662936,\n",
      "    \"fg*:3\": 46.16692756808881,\n",
      "    \"bg*:3\": 51.83121889017516\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "imageCount = 0\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for log_id in log_ids:\n",
    "    # Path to the predicted disparity maps.\n",
    "    save_dir_disp = f'./results/PSMNet_results/{log_id}/'\n",
    "    pred_dir = Path(save_dir_disp)\n",
    "\n",
    "    # Path to the ground-truth disparity maps.\n",
    "    gt_dir = Path(f\"{data_dir}/disparity_maps_v1.1/{split_name}/{log_id}\")\n",
    "\n",
    "    # Path to save the disparity error image.\n",
    "    save_figures_dir = Path(f'./results/PSMNet_error_results/')\n",
    "    save_figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Creating the stereo evaluator.\n",
    "    evaluator = StereoEvaluator(\n",
    "        pred_dir,\n",
    "        gt_dir,\n",
    "        save_figures_dir,\n",
    "        save_disparity_error_image=True,\n",
    "        num_procs=-1,\n",
    "    )\n",
    "\n",
    "    # Running the stereo evaluation.\n",
    "    metrics, data, errors = evaluator.evaluate(data)\n",
    "    print('Elapsed Time:', time.time()-t0)\n",
    "    \n",
    "# Printing the quantitative results (using json trick for organized printing).\n",
    "print('Results for Full Images')\n",
    "print('==============================')\n",
    "print(f\"{json.dumps(metrics, sort_keys=False, indent=4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c477a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573b3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
